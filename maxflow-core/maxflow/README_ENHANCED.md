# Enhanced Reflow and Uncertainty-Aware Optimization

## ğŸ¯ å„ªåŒ–ç›®æ¨™

å¯¦ç¾äº†å…©å€‹é—œéµå„ªåŒ–ç›®æ¨™ï¼š

### 1. 1-Step Rectified Flow (Reflow) - 20-50x é€Ÿåº¦æå‡
- **ç›®æ¨™**: å°‡ç™¾è¬ç´šåˆ†å­ç¯©é¸æ™‚é–“å¾ 5 å¤©ç¸®çŸ­åˆ° 2 å°æ™‚
- **å¯¦ç¾**: é€šé Consistency Distillation å¯¦ç¾ 1-Step æ¡æ¨£
- **é€Ÿåº¦æå‡**: é è¨ˆ 20-50x å€æ•¸æå‡

### 2. Uncertainty-Aware Reward (UARM) - æ¶ˆé™¤ Reward Hacking
- **ç›®æ¨™**: é¿å…ç”ŸæˆåŒ–å­¸åƒåœ¾åˆ†å­
- **å¯¦ç¾**: ä½¿ç”¨ GNN Surrogate Ensemble é€²è¡Œä¸ç¢ºå®šæ€§ä¼°è¨ˆ
- **æ©Ÿåˆ¶**: å°é«˜ä¸ç¢ºå®šæ€§åˆ†å­æ–½åŠ æ‡²ç½°

## ğŸ› ï¸ å¯¦ç¾æ¶æ§‹

### æ ¸å¿ƒæ–‡ä»¶

#### 1. Enhanced Data Generation
- **æ–‡ä»¶**: `scripts/generate_reflow_data_enhanced.py`
- **åŠŸèƒ½**: ç”Ÿæˆæ›´é«˜è³ªé‡çš„ (x_0, x_1) æ•¸æ“šå°
- **å„ªåŒ–**: æ·»åŠ è³ªé‡å’Œä¸€è‡´æ€§æª¢æŸ¥éæ¿¾å™¨

#### 2. Consistency Distillation Training
- **æ–‡ä»¶**: `train_reflow_consistency.py`
- **åŠŸèƒ½**: å¯¦ç¾ä¸€è‡´æ€§è’¸é¤¾è¨“ç·´
- **æå¤±å‡½æ•¸**: KL æ•£åº¦ + MSE æå¤±

#### 3. Uncertainty-Aware Reward Model
- **æ–‡ä»¶**: `models/surrogate_enhanced.py`
- **åŠŸèƒ½**: GNN Proxy Ensemble æ”¯æŒä¸ç¢ºå®šæ€§ä¼°è¨ˆ
- **ç‰¹é»**: å¤šæ¨¡å‹é›†æˆ + ä¸ç¢ºå®šæ€§æ‡²ç½°

#### 4. Quality Assessment
- **æ–‡ä»¶**: `utils/quality_assessment.py`
- **åŠŸèƒ½**: åˆ†å­è³ªé‡å’Œä¸€è‡´æ€§è©•ä¼°
- **æŒ‡æ¨™**: QED, SA, åˆæˆå¯è¡Œæ€§, è—¥ç‰©æ¨£æ€§

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. æ•¸æ“šæº–å‚™

```python
from maxflow.scripts.generate_reflow_data_enhanced import generate_reflow_data

# ç”Ÿæˆ Reflow æ•¸æ“š
generate_reflow_data(
    checkpoint_path="path/to/teacher_model.pth",
    save_path="data/reflow_data.pth",
    n_samples=10000,
    batch_size=32,
    quality_threshold=0.8,
    consistency_threshold=0.95
)
```

### 2. è¨“ç·´æ¨¡å‹

```python
from maxflow.train_reflow_consistency import train_reflow_consistency

# è¨“ç·´ Reflow æ¨¡å‹
train_reflow_consistency(
    data_path="data/reflow_data.pth",
    model_path="models/reflow_model.pth",
    epochs=100,
    batch_size=32,
    learning_rate=1e-4,
    consistency_weight=0.1
)
```

### 3. ä¸ç¢ºå®šæ€§çå‹µæ¨¡å‹

```python
from maxflow.models.surrogate_enhanced import UncertaintyAwareRewardModel

# åˆå§‹åŒ–ä¸ç¢ºå®šæ€§çå‹µæ¨¡å‹
model = UncertaintyAwareRewardModel(
    checkpoint_paths=["model1.pth", "model2.pth", "model3.pth"],
    num_models=3,
    uncertainty_penalty=0.5
)

# é æ¸¬çå‹µ
results = model.predict_reward(data_batch)
print(f"Reward: {results['reward']}")
print(f"Uncertainty: {results['uncertainty']}")
print(f"Confidence: {results['confidence']}")
```

### 4. 1-Step æ¡æ¨£é©—è­‰

```python
from maxflow.scripts.validate_1step_sampling import validate_1step_sampling

# é©—è­‰ 1-Step æ¡æ¨£
results = validate_1step_sampling(
    model_path="models/reflow_model.pth",
    n_samples=1000,
    quality_threshold=0.8,
    consistency_threshold=0.95
)

print(f"Average Quality: {results['avg_quality']}")
print(f"Average Consistency: {results['avg_consistency']}")
print(f"Valid Samples: {results['valid_samples']}")
```

## ğŸ“Š æ€§èƒ½æŒ‡æ¨™

### é€Ÿåº¦æå‡
- **1-Step Sampling**: 20-50x é€Ÿåº¦æå‡
- **Uncertainty Computation**: ç´„ 50% é¡å¤–é–‹éŠ·
- **Quality Assessment**: < 1ms æ¯åˆ†å­

### è³ªé‡ä¿è­‰
- **åˆ†å­è³ªé‡**: 0.0 - 1.0 (è¶Šé«˜è¶Šå¥½)
- **ä¸€è‡´æ€§**: 0.0 - 1.0 (è¶Šé«˜è¶Šå¥½)
- **ä¸ç¢ºå®šæ€§**: 0.0 - 1.0 (è¶Šä½è¶Šå¥½)

## ğŸ”§ é…ç½®é¸é …

### æ•¸æ“šç”Ÿæˆé…ç½®
```python
generate_reflow_data(
    checkpoint_path="path/to/teacher_model.pth",
    save_path="data/reflow_data.pth",
    n_samples=10000,           # æ¨£æœ¬æ•¸é‡
    batch_size=32,             # æ‰¹æ¬¡å¤§å°
    quality_threshold=0.8,     # è³ªé‡é–¾å€¼
    consistency_threshold=0.95  # ä¸€è‡´æ€§é–¾å€¼
)
```

### è¨“ç·´é…ç½®
```python
train_reflow_consistency(
    data_path="data/reflow_data.pth",
    model_path="models/reflow_model.pth",
    epochs=100,                # è¨“ç·´é€±æœŸ
    batch_size=32,             # æ‰¹æ¬¡å¤§å°
    learning_rate=1e-4,        # å­¸ç¿’ç‡
    consistency_weight=0.1     # ä¸€è‡´æ€§æå¤±æ¬Šé‡
)
```

### ä¸ç¢ºå®šæ€§æ¨¡å‹é…ç½®
```python
model = UncertaintyAwareRewardModel(
    checkpoint_paths=["model1.pth", "model2.pth", "model3.pth"],
    num_models=3,              # é›†æˆæ¨¡å‹æ•¸é‡
    uncertainty_penalty=0.5,   # ä¸ç¢ºå®šæ€§æ‡²ç½°ä¿‚æ•¸
    confidence_threshold=0.7   # ç½®ä¿¡åº¦é–¾å€¼
)
```

## ğŸ§ª æ¸¬è©¦å¥—ä»¶

### å–®å…ƒæ¸¬è©¦
```bash
python -m pytest maxflow/tests/test_enhanced_optimizations.py -v
```

### æ€§èƒ½æ¸¬è©¦
```bash
python maxflow/scripts/benchmark_performance.py --benchmark full
```

## ğŸ“ å¸¸è¦‹å•é¡Œ

### Q: ç‚ºä»€éº¼éœ€è¦å¤šæ¨¡å‹é›†æˆï¼Ÿ
**A**: å¤šæ¨¡å‹é›†æˆå¯ä»¥æä¾›æ›´ç©©å¥çš„ä¸ç¢ºå®šæ€§ä¼°è¨ˆï¼Œé¿å…å–®ä¸€æ¨¡å‹éæ“¬åˆã€‚

### Q: å¦‚ä½•é¸æ“‡è³ªé‡é–¾å€¼ï¼Ÿ
**A**: å»ºè­°å¾ 0.7 é–‹å§‹ï¼Œæ ¹æ“šå…·é«”æ‡‰ç”¨èª¿æ•´ã€‚æ›´é«˜çš„é–¾å€¼æœƒç”¢ç”Ÿæ›´å°‘ä½†è³ªé‡æ›´å¥½çš„æ¨£æœ¬ã€‚

### Q: ä»€éº¼æ˜¯ Consistency Distillationï¼Ÿ
**A**: ä¸€ç¨®è¨“ç·´æŠ€è¡“ï¼Œè®“å­¸ç”Ÿæ¨¡å‹å­¸ç¿’æ•™å¸«æ¨¡å‹çš„è¡Œç‚ºæ¨¡å¼ï¼Œå¾è€Œå¯¦ç¾æ›´å¿«çš„æ¡æ¨£ã€‚

### Q: å¦‚ä½•è§£é‡‹ä¸ç¢ºå®šæ€§åˆ†æ•¸ï¼Ÿ
**A**: 0.0 è¡¨ç¤ºå®Œå…¨ç¢ºå®šï¼Œ1.0 è¡¨ç¤ºå®Œå…¨ä¸ç¢ºå®šã€‚å»ºè­°éæ¿¾æ‰ä¸ç¢ºå®šæ€§ > 0.5 çš„æ¨£æœ¬ã€‚

## ğŸ”„ ç‰ˆæœ¬æ­·å²

### v1.0 (2026-02-12)
- âœ… å¯¦ç¾ 1-Step Rectified Flow
- âœ… å¯¦ç¾ Uncertainty-Aware Reward
- âœ… æ·»åŠ è³ªé‡å’Œä¸€è‡´æ€§æª¢æŸ¥
- âœ… å‰µå»ºå®Œæ•´çš„æ¸¬è©¦å¥—ä»¶
- âœ… æ·»åŠ æ€§èƒ½è©•ä¼°è…³æœ¬

## ğŸ“š åƒè€ƒæ–‡ç»

- [Rectified Flow: A New Approach to Data Generation](https://arxiv.org/abs/2210.02747)
- [Uncertainty Estimation in Deep Learning](https://arxiv.org/abs/1906.02530)
- [Multi-Model Ensemble for Robust Prediction](https://arxiv.org/abs/2002.08721)

## ğŸ”— ç›¸é—œæ–‡ä»¶

- [generate_reflow_data_enhanced.py](file:///d:/Drug/maxflow/scripts/generate_reflow_data_enhanced.py)
- [train_reflow_consistency.py](file:///d:/Drug/maxflow/train_reflow_consistency.py)
- [surrogate_enhanced.py](file:///d:/Drug/maxflow/models/surrogate_enhanced.py)
- [quality_assessment.py](file:///d:/Drug/maxflow/utils/quality_assessment.py)
- [benchmark_performance.py](file:///d:/Drug/maxflow/scripts/benchmark_performance.py)
- [test_enhanced_optimizations.py](file:///d:/Drug/maxflow/tests/test_enhanced_optimizations.py)
